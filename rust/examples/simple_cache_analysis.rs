//! Simplified cache performance analysis

use bplustree::BPlusTreeMap;
use std::collections::BTreeMap;
use std::hint::black_box;
use std::time::Instant;

fn main() {
    println!("‚ö° CACHE PERFORMANCE ANALYSIS");
    println!("=============================");

    let size = 50_000;

    // 1. SEQUENTIAL ITERATION (CACHE-FRIENDLY)
    println!("\nüîÑ SEQUENTIAL ITERATION");
    println!("{}", "=".repeat(40));

    // Create trees
    let btree: BTreeMap<i32, i32> = (0..size).map(|i| (i, i * 2)).collect();
    let mut bplus = BPlusTreeMap::new(64).unwrap();
    for i in 0..size {
        bplus.insert(i, i * 2);
    }

    // Sequential iteration
    let start = Instant::now();
    let mut sum = 0i64;
    for (k, v) in btree.iter() {
        sum += (*k as i64) + (*v as i64);
    }
    black_box(sum);
    let btree_sequential = start.elapsed();

    let start = Instant::now();
    let mut sum = 0i64;
    for (k, v) in bplus.items() {
        sum += (*k as i64) + (*v as i64);
    }
    black_box(sum);
    let bplus_sequential = start.elapsed();

    println!("Sequential iteration ({} items):", size);
    println!(
        "  BTreeMap: {:.2}ms",
        btree_sequential.as_secs_f64() * 1000.0
    );
    println!(
        "  BPlusTreeMap: {:.2}ms",
        bplus_sequential.as_secs_f64() * 1000.0
    );

    let seq_ratio = btree_sequential.as_secs_f64() / bplus_sequential.as_secs_f64();
    if seq_ratio > 1.0 {
        println!("  ‚úÖ BPlusTreeMap is {:.2}x FASTER", seq_ratio);
    } else {
        println!("  ‚ùå BPlusTreeMap is {:.2}x SLOWER", 1.0 / seq_ratio);
    }

    // 2. RANDOM ACCESS (CACHE-UNFRIENDLY)
    println!("\nüé≤ RANDOM ACCESS");
    println!("{}", "=".repeat(40));

    let random_keys: Vec<i32> = (0..10_000).map(|i| (i * 7) % size).collect();

    let start = Instant::now();
    let mut sum = 0i64;
    for &key in &random_keys {
        if let Some(value) = btree.get(&key) {
            sum += (key as i64) + (*value as i64);
        }
    }
    black_box(sum);
    let btree_random = start.elapsed();

    let start = Instant::now();
    let mut sum = 0i64;
    for &key in &random_keys {
        if let Some(value) = bplus.get(&key) {
            sum += (key as i64) + (*value as i64);
        }
    }
    black_box(sum);
    let bplus_random = start.elapsed();

    println!("Random access ({} lookups):", random_keys.len());
    println!("  BTreeMap: {:.2}ms", btree_random.as_secs_f64() * 1000.0);
    println!(
        "  BPlusTreeMap: {:.2}ms",
        bplus_random.as_secs_f64() * 1000.0
    );

    let random_ratio = btree_random.as_secs_f64() / bplus_random.as_secs_f64();
    if random_ratio > 1.0 {
        println!("  ‚úÖ BPlusTreeMap is {:.2}x FASTER", random_ratio);
    } else {
        println!("  ‚ùå BPlusTreeMap is {:.2}x SLOWER", 1.0 / random_ratio);
    }

    // 3. MEMORY LAYOUT IMPACT
    println!("\nüíæ MEMORY LAYOUT IMPACT");
    println!("{}", "=".repeat(40));

    use std::mem;

    let cache_line_size = 64;
    println!("Cache line analysis (64-byte cache lines):");
    println!(
        "  BTreeMap size: {} bytes",
        mem::size_of::<BTreeMap<i32, i32>>()
    );
    println!(
        "  BPlusTreeMap size: {} bytes",
        mem::size_of::<BPlusTreeMap<i32, i32>>()
    );

    let btree_per_line = cache_line_size / mem::size_of::<BTreeMap<i32, i32>>();
    let bplus_per_line = cache_line_size / mem::size_of::<BPlusTreeMap<i32, i32>>();

    println!("  BTreeMaps per cache line: {}", btree_per_line);
    println!("  BPlusTreeMaps per cache line: {}", bplus_per_line);

    if btree_per_line > bplus_per_line {
        println!("  ‚úÖ BTreeMap has better cache line utilization");
    } else if bplus_per_line > btree_per_line {
        println!("  ‚úÖ BPlusTreeMap has better cache line utilization");
    } else {
        println!("  ‚Üí Equal cache line utilization");
    }

    // 4. CACHE MISS SIMULATION
    println!("\nüéØ CACHE BEHAVIOR SIMULATION");
    println!("{}", "=".repeat(40));

    // Test with different access patterns
    let small_data: Vec<i32> = (0..1000).collect();
    let large_data: Vec<i32> = (0..1_000_000).collect();

    // Small data (likely fits in cache)
    let start = Instant::now();
    let mut sum = 0i64;
    for &x in &small_data {
        sum += x as i64;
    }
    black_box(sum);
    let small_time = start.elapsed();

    // Large data (likely causes cache misses)
    let start = Instant::now();
    let mut sum = 0i64;
    for &x in &large_data {
        sum += x as i64;
    }
    black_box(sum);
    let large_time = start.elapsed();

    println!("Sequential access patterns:");
    println!(
        "  Small data (1k items): {:.2}ms",
        small_time.as_secs_f64() * 1000.0
    );
    println!(
        "  Large data (1M items): {:.2}ms",
        large_time.as_secs_f64() * 1000.0
    );

    let cache_impact = (large_time.as_secs_f64() / large_data.len() as f64)
        / (small_time.as_secs_f64() / small_data.len() as f64);
    println!(
        "  Cache impact factor: {:.2}x slower per item",
        cache_impact
    );

    // 5. OPTIMIZATION IMPACT ON CACHE
    println!("\nüöÄ OPTIMIZATION IMPACT ON CACHE");
    println!("{}", "=".repeat(40));

    println!("Memory optimization benefits for cache performance:");
    println!("‚úÖ Smaller structures ‚Üí better cache line utilization");
    println!("‚úÖ Reduced memory footprint ‚Üí less cache pressure");
    println!("‚úÖ Better spatial locality ‚Üí fewer cache misses");

    let original_stack = 176;
    let optimized_stack = 104; // Estimated after optimizations
    let cache_improvement = original_stack as f64 / optimized_stack as f64;

    println!("\nEstimated cache improvements:");
    println!(
        "  Stack size reduction: {}B ‚Üí {}B",
        original_stack, optimized_stack
    );
    println!("  Cache efficiency improvement: {:.2}x", cache_improvement);
    println!("  More structures fit in cache lines");

    // 6. PERFORMANCE SUMMARY
    println!("\nüìä CACHE PERFORMANCE SUMMARY");
    println!("{}", "=".repeat(40));

    println!("Operation        | BTreeMap | BPlusTreeMap | Winner");
    println!("-----------------|----------|--------------|--------");
    println!(
        "Sequential       | {:6.2}ms | {:10.2}ms | {}",
        btree_sequential.as_secs_f64() * 1000.0,
        bplus_sequential.as_secs_f64() * 1000.0,
        if seq_ratio > 1.0 { "BPlus" } else { "BTree" }
    );

    println!(
        "Random Access    | {:6.2}ms | {:10.2}ms | {}",
        btree_random.as_secs_f64() * 1000.0,
        bplus_random.as_secs_f64() * 1000.0,
        if random_ratio > 1.0 { "BPlus" } else { "BTree" }
    );

    // 7. RECOMMENDATIONS
    println!("\nüéØ CACHE PERFORMANCE RECOMMENDATIONS");
    println!("{}", "=".repeat(40));

    let overall_cache_friendly = seq_ratio >= 0.9 && random_ratio >= 0.9;

    if overall_cache_friendly {
        println!("‚úÖ RECOMMENDATION: Optimizations improve cache performance");
        println!("   ‚Ä¢ Sequential access: Good performance");
        println!("   ‚Ä¢ Random access: Competitive performance");
        println!("   ‚Ä¢ Memory optimizations provide cache benefits");
    } else {
        println!("‚ö†Ô∏è  RECOMMENDATION: Mixed cache performance results");
        println!("   ‚Ä¢ Some access patterns benefit more than others");
        println!("   ‚Ä¢ Consider workload characteristics");
    }

    println!("\nKey insights:");
    println!("‚Ä¢ Memory layout significantly affects cache performance");
    println!("‚Ä¢ Smaller structures generally improve cache efficiency");
    println!("‚Ä¢ Access patterns matter more than structure size");
    println!("‚Ä¢ Optimizations provide both memory and cache benefits");
}
