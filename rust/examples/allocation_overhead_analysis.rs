//! Allocation and deallocation overhead analysis

use bplustree::{BPlusTreeMap, OptimizedArena, CompactArena};
use std::collections::BTreeMap;
use std::time::Instant;
use std::hint::black_box;

fn benchmark_btree_allocation_overhead(iterations: usize) -> std::time::Duration {
    let start = Instant::now();
    
    for i in 0..iterations {
        let mut btree = BTreeMap::new();
        
        // Insert some items to trigger allocations
        for j in 0..10 {
            btree.insert(i * 10 + j, j);
        }
        
        black_box(btree);
        // BTreeMap automatically deallocates when dropped
    }
    
    start.elapsed()
}

fn benchmark_bplus_allocation_overhead(iterations: usize) -> std::time::Duration {
    let start = Instant::now();
    
    for i in 0..iterations {
        let mut bplus = BPlusTreeMap::new(16).unwrap();
        
        // Insert some items to trigger allocations
        for j in 0..10 {
            bplus.insert(i * 10 + j, j);
        }
        
        black_box(bplus);
        // BPlusTreeMap automatically deallocates when dropped
    }
    
    start.elapsed()
}

fn benchmark_arena_allocation_patterns() {
    println!("üèóÔ∏è ARENA ALLOCATION PATTERNS");
    println!("{}", "=".repeat(40));
    
    let iterations = 10_000;
    
    // Test OptimizedArena
    let start = Instant::now();
    let mut opt_arena = OptimizedArena::new();
    let mut opt_ids = Vec::new();
    
    for i in 0..iterations {
        let id = opt_arena.allocate(i);
        opt_ids.push(id);
    }
    
    // Deallocate half
    for i in (0..iterations).step_by(2) {
        opt_arena.deallocate(opt_ids[i]);
    }
    
    let opt_time = start.elapsed();
    
    // Test CompactArena
    let start = Instant::now();
    let mut comp_arena = CompactArena::new();
    let mut comp_ids = Vec::new();
    
    for i in 0..iterations {
        let id = comp_arena.allocate(i);
        comp_ids.push(id);
    }
    
    // Deallocate half
    for i in (0..iterations).step_by(2) {
        comp_arena.deallocate(comp_ids[i]);
    }
    
    let comp_time = start.elapsed();
    
    println!("Arena allocation/deallocation ({} operations):", iterations);
    println!("  OptimizedArena: {:.2}ms", opt_time.as_secs_f64() * 1000.0);
    println!("  CompactArena: {:.2}ms", comp_time.as_secs_f64() * 1000.0);
    
    let arena_ratio = comp_time.as_secs_f64() / opt_time.as_secs_f64();
    if arena_ratio > 1.0 {
        println!("  ‚úÖ OptimizedArena is {:.2}x FASTER", arena_ratio);
    } else {
        println!("  ‚ùå OptimizedArena is {:.2}x SLOWER", 1.0 / arena_ratio);
    }
    
    // Check final stats
    let opt_stats = opt_arena.stats();
    let comp_stats = comp_arena.stats();
    
    println!("\nFinal arena statistics:");
    println!("  OptimizedArena: {} allocated, {:.1}% utilization", 
             opt_stats.allocated_count, opt_stats.utilization * 100.0);
    println!("  CompactArena: {} allocated, {:.1}% utilization", 
             comp_stats.allocated_count, comp_stats.utilization * 100.0);
}

fn benchmark_memory_fragmentation() {
    println!("\nüß© MEMORY FRAGMENTATION ANALYSIS");
    println!("{}", "=".repeat(40));
    
    let cycles = 5;
    let items_per_cycle = 1000;
    
    // Test fragmentation with OptimizedArena
    let mut opt_arena = OptimizedArena::new();
    let start = Instant::now();
    
    for cycle in 0..cycles {
        let mut ids = Vec::new();
        
        // Allocate
        for i in 0..items_per_cycle {
            let id = opt_arena.allocate(cycle * items_per_cycle + i);
            ids.push(id);
        }
        
        // Deallocate every other item (creates fragmentation)
        for i in (0..items_per_cycle).step_by(2) {
            opt_arena.deallocate(ids[i]);
        }
    }
    
    let opt_frag_time = start.elapsed();
    let opt_final_stats = opt_arena.stats();
    
    // Test fragmentation with CompactArena
    let mut comp_arena = CompactArena::new();
    let start = Instant::now();
    
    for cycle in 0..cycles {
        let mut ids = Vec::new();
        
        // Allocate
        for i in 0..items_per_cycle {
            let id = comp_arena.allocate(cycle * items_per_cycle + i);
            ids.push(id);
        }
        
        // Deallocate every other item (creates fragmentation)
        for i in (0..items_per_cycle).step_by(2) {
            comp_arena.deallocate(ids[i]);
        }
    }
    
    let comp_frag_time = start.elapsed();
    let comp_final_stats = comp_arena.stats();
    
    println!("Fragmentation test ({} cycles, {} items each):", cycles, items_per_cycle);
    println!("  OptimizedArena: {:.2}ms", opt_frag_time.as_secs_f64() * 1000.0);
    println!("  CompactArena: {:.2}ms", comp_frag_time.as_secs_f64() * 1000.0);
    
    let frag_ratio = comp_frag_time.as_secs_f64() / opt_frag_time.as_secs_f64();
    if frag_ratio > 1.0 {
        println!("  ‚úÖ OptimizedArena handles fragmentation {:.2}x FASTER", frag_ratio);
    } else {
        println!("  ‚ùå OptimizedArena handles fragmentation {:.2}x SLOWER", 1.0 / frag_ratio);
    }
    
    println!("\nFragmentation impact:");
    println!("  OptimizedArena utilization: {:.1}%", opt_final_stats.utilization * 100.0);
    println!("  CompactArena utilization: {:.1}%", comp_final_stats.utilization * 100.0);
}

fn benchmark_allocation_size_impact() {
    println!("\nüìè ALLOCATION SIZE IMPACT");
    println!("{}", "=".repeat(40));
    
    // Test different allocation sizes
    let iterations = 1000;
    
    // Small allocations (i32)
    let start = Instant::now();
    let mut small_arena = OptimizedArena::<i32>::new();
    for i in 0..iterations {
        small_arena.allocate(i);
    }
    let small_time = start.elapsed();
    
    // Medium allocations (array of 4 i32s)
    let start = Instant::now();
    let mut medium_arena = OptimizedArena::<[i32; 4]>::new();
    for i in 0..iterations {
        medium_arena.allocate([i, i+1, i+2, i+3]);
    }
    let medium_time = start.elapsed();
    
    // Large allocations (array of 64 i32s)
    let start = Instant::now();
    let mut large_arena = OptimizedArena::<[i32; 64]>::new();
    for i in 0..iterations {
        let mut arr = [0i32; 64];
        arr[0] = i;
        large_arena.allocate(arr);
    }
    let large_time = start.elapsed();
    
    println!("Allocation size impact ({} allocations):", iterations);
    println!("  Small (4B): {:.2}ms", small_time.as_secs_f64() * 1000.0);
    println!("  Medium (16B): {:.2}ms", medium_time.as_secs_f64() * 1000.0);
    println!("  Large (256B): {:.2}ms", large_time.as_secs_f64() * 1000.0);
    
    println!("\nPer-byte allocation cost:");
    println!("  Small: {:.2}ns/byte", small_time.as_nanos() as f64 / (iterations * 4) as f64);
    println!("  Medium: {:.2}ns/byte", medium_time.as_nanos() as f64 / (iterations * 16) as f64);
    println!("  Large: {:.2}ns/byte", large_time.as_nanos() as f64 / (iterations * 256) as f64);
}

fn main() {
    println!("üí∞ ALLOCATION/DEALLOCATION OVERHEAD ANALYSIS");
    println!("============================================");
    
    let iterations = 1000;
    
    // 1. TREE ALLOCATION OVERHEAD
    println!("\nüìä TREE ALLOCATION OVERHEAD");
    println!("{}", "=".repeat(40));
    
    let btree_time = benchmark_btree_allocation_overhead(iterations);
    let bplus_time = benchmark_bplus_allocation_overhead(iterations);
    
    println!("Tree creation/destruction ({} iterations):", iterations);
    println!("  BTreeMap: {:.2}ms", btree_time.as_secs_f64() * 1000.0);
    println!("  BPlusTreeMap: {:.2}ms", bplus_time.as_secs_f64() * 1000.0);
    
    let tree_ratio = bplus_time.as_secs_f64() / btree_time.as_secs_f64();
    if tree_ratio > 1.0 {
        println!("  ‚ùå BPlusTreeMap is {:.2}x SLOWER at allocation", tree_ratio);
    } else {
        println!("  ‚úÖ BPlusTreeMap is {:.2}x FASTER at allocation", 1.0 / tree_ratio);
    }
    
    println!("\nPer-tree allocation cost:");
    println!("  BTreeMap: {:.2}Œºs per tree", btree_time.as_micros() as f64 / iterations as f64);
    println!("  BPlusTreeMap: {:.2}Œºs per tree", bplus_time.as_micros() as f64 / iterations as f64);
    
    // 2. ARENA ALLOCATION PATTERNS
    benchmark_arena_allocation_patterns();
    
    // 3. MEMORY FRAGMENTATION
    benchmark_memory_fragmentation();
    
    // 4. ALLOCATION SIZE IMPACT
    benchmark_allocation_size_impact();
    
    // 5. OPTIMIZATION IMPACT ON ALLOCATION
    println!("\nüöÄ OPTIMIZATION IMPACT ON ALLOCATION");
    println!("{}", "=".repeat(40));
    
    println!("Memory optimization benefits for allocation:");
    println!("‚úÖ OptimizedArena: Simpler allocation logic");
    println!("‚úÖ Reduced metadata overhead per allocation");
    println!("‚úÖ Better cache locality during allocation");
    println!("‚úÖ Fewer memory management operations");
    
    // Estimate allocation overhead reduction
    use std::mem;
    let original_arena_size = 80; // CompactArena size
    let optimized_arena_size = mem::size_of::<OptimizedArena<i32>>();
    let overhead_reduction = (original_arena_size - optimized_arena_size) as f64 / original_arena_size as f64;
    
    println!("\nAllocation overhead improvements:");
    println!("  Arena size reduction: {}B ‚Üí {}B", original_arena_size, optimized_arena_size);
    println!("  Overhead reduction: {:.1}%", overhead_reduction * 100.0);
    println!("  Fewer allocator calls per operation");
    
    // 6. PERFORMANCE SUMMARY
    println!("\nüìà ALLOCATION PERFORMANCE SUMMARY");
    println!("{}", "=".repeat(40));
    
    println!("Operation           | Time     | Winner");
    println!("--------------------|----------|--------");
    println!("Tree Creation       | BTree: {:.2}ms, BPlus: {:.2}ms | {}",
             btree_time.as_secs_f64() * 1000.0,
             bplus_time.as_secs_f64() * 1000.0,
             if tree_ratio < 1.0 { "BPlus" } else { "BTree" });
    
    // 7. RECOMMENDATIONS
    println!("\nüéØ ALLOCATION OVERHEAD RECOMMENDATIONS");
    println!("{}", "=".repeat(40));
    
    if tree_ratio <= 1.2 { // Within 20% is acceptable
        println!("‚úÖ RECOMMENDATION: Allocation overhead is acceptable");
        println!("   ‚Ä¢ BPlusTreeMap allocation cost is competitive");
        println!("   ‚Ä¢ Memory optimizations provide allocation benefits");
        println!("   ‚Ä¢ Arena optimizations improve allocation patterns");
    } else {
        println!("‚ö†Ô∏è  RECOMMENDATION: Consider allocation optimization");
        println!("   ‚Ä¢ BPlusTreeMap has higher allocation overhead");
        println!("   ‚Ä¢ May impact performance for frequent creation/destruction");
        println!("   ‚Ä¢ Consider object pooling for high-frequency use cases");
    }
    
    println!("\nKey insights:");
    println!("‚Ä¢ Arena-based allocation is generally efficient");
    println!("‚Ä¢ OptimizedArena reduces allocation overhead");
    println!("‚Ä¢ Memory layout affects allocation performance");
    println!("‚Ä¢ Fragmentation handling varies between implementations");
    println!("‚Ä¢ Allocation size has minimal impact on per-byte cost");
}
