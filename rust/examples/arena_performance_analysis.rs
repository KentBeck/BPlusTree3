//! Performance analysis of OptimizedArena vs CompactArena

use bplustree::{OptimizedArena, CompactArena};
use std::time::Instant;
use std::hint::black_box;

fn benchmark_allocation_optimized(iterations: usize) -> std::time::Duration {
    let mut arena = OptimizedArena::new();
    
    let start = Instant::now();
    
    for i in 0..iterations {
        let id = arena.allocate(i);
        black_box(id);
    }
    
    start.elapsed()
}

fn benchmark_allocation_compact(iterations: usize) -> std::time::Duration {
    let mut arena = CompactArena::new();
    
    let start = Instant::now();
    
    for i in 0..iterations {
        let id = arena.allocate(i);
        black_box(id);
    }
    
    start.elapsed()
}

fn benchmark_access_optimized(arena: &OptimizedArena<i32>, ids: &[u32]) -> std::time::Duration {
    let start = Instant::now();
    
    let mut sum = 0i64;
    for &id in ids {
        if let Some(value) = arena.get(id) {
            sum += *value as i64;
        }
    }
    black_box(sum);
    
    start.elapsed()
}

fn benchmark_access_compact(arena: &CompactArena<i32>, ids: &[u32]) -> std::time::Duration {
    let start = Instant::now();
    
    let mut sum = 0i64;
    for &id in ids {
        if let Some(value) = arena.get(id) {
            sum += *value as i64;
        }
    }
    black_box(sum);
    
    start.elapsed()
}

fn benchmark_mixed_operations_optimized(iterations: usize) -> std::time::Duration {
    let mut arena = OptimizedArena::new();
    let mut allocated_ids = Vec::new();
    
    let start = Instant::now();
    
    for i in 0..iterations {
        if i % 3 == 0 && !allocated_ids.is_empty() {
            // Deallocate
            let id = allocated_ids.pop().unwrap();
            arena.deallocate(id);
        } else {
            // Allocate
            let id = arena.allocate(i);
            allocated_ids.push(id);
        }
        
        // Access some items
        if i % 10 == 0 && !allocated_ids.is_empty() {
            let id = allocated_ids[allocated_ids.len() / 2];
            black_box(arena.get(id));
        }
    }
    
    start.elapsed()
}

fn benchmark_mixed_operations_compact(iterations: usize) -> std::time::Duration {
    let mut arena = CompactArena::new();
    let mut allocated_ids = Vec::new();
    
    let start = Instant::now();
    
    for i in 0..iterations {
        if i % 3 == 0 && !allocated_ids.is_empty() {
            // Deallocate
            let id = allocated_ids.pop().unwrap();
            arena.deallocate(id);
        } else {
            // Allocate
            let id = arena.allocate(i);
            allocated_ids.push(id);
        }
        
        // Access some items
        if i % 10 == 0 && !allocated_ids.is_empty() {
            let id = allocated_ids[allocated_ids.len() / 2];
            black_box(arena.get(id));
        }
    }
    
    start.elapsed()
}

fn main() {
    println!("üèóÔ∏è ARENA PERFORMANCE ANALYSIS");
    println!("==============================");
    
    let iterations = 100_000;
    
    // 1. ALLOCATION PERFORMANCE
    println!("\nüìä ALLOCATION PERFORMANCE ({} iterations)", iterations);
    println!("{}", "=".repeat(50));
    
    let optimized_alloc = benchmark_allocation_optimized(iterations);
    let compact_alloc = benchmark_allocation_compact(iterations);
    
    println!("OptimizedArena allocation: {:.2}ms", optimized_alloc.as_secs_f64() * 1000.0);
    println!("CompactArena allocation: {:.2}ms", compact_alloc.as_secs_f64() * 1000.0);
    
    let alloc_ratio = compact_alloc.as_secs_f64() / optimized_alloc.as_secs_f64();
    if alloc_ratio > 1.0 {
        println!("‚úÖ OptimizedArena is {:.2}x FASTER at allocation", alloc_ratio);
    } else {
        println!("‚ùå OptimizedArena is {:.2}x SLOWER at allocation", 1.0 / alloc_ratio);
    }
    
    // 2. ACCESS PERFORMANCE
    println!("\nüîç ACCESS PERFORMANCE");
    println!("{}", "=".repeat(50));
    
    // Set up test data
    let mut optimized_arena = OptimizedArena::new();
    let mut compact_arena = CompactArena::new();
    let mut ids = Vec::new();
    
    for i in 0..10_000 {
        let opt_id = optimized_arena.allocate(i);
        let comp_id = compact_arena.allocate(i);
        ids.push(opt_id);
        assert_eq!(opt_id, comp_id); // Should be same IDs
    }
    
    let optimized_access = benchmark_access_optimized(&optimized_arena, &ids);
    let compact_access = benchmark_access_compact(&compact_arena, &ids);
    
    println!("OptimizedArena access: {:.2}ms", optimized_access.as_secs_f64() * 1000.0);
    println!("CompactArena access: {:.2}ms", compact_access.as_secs_f64() * 1000.0);
    
    let access_ratio = compact_access.as_secs_f64() / optimized_access.as_secs_f64();
    if access_ratio > 1.0 {
        println!("‚úÖ OptimizedArena is {:.2}x FASTER at access", access_ratio);
    } else {
        println!("‚ùå OptimizedArena is {:.2}x SLOWER at access", 1.0 / access_ratio);
    }
    
    // 3. MIXED OPERATIONS PERFORMANCE
    println!("\nüîÑ MIXED OPERATIONS PERFORMANCE");
    println!("{}", "=".repeat(50));
    
    let optimized_mixed = benchmark_mixed_operations_optimized(iterations);
    let compact_mixed = benchmark_mixed_operations_compact(iterations);
    
    println!("OptimizedArena mixed ops: {:.2}ms", optimized_mixed.as_secs_f64() * 1000.0);
    println!("CompactArena mixed ops: {:.2}ms", compact_mixed.as_secs_f64() * 1000.0);
    
    let mixed_ratio = compact_mixed.as_secs_f64() / optimized_mixed.as_secs_f64();
    if mixed_ratio > 1.0 {
        println!("‚úÖ OptimizedArena is {:.2}x FASTER at mixed operations", mixed_ratio);
    } else {
        println!("‚ùå OptimizedArena is {:.2}x SLOWER at mixed operations", 1.0 / mixed_ratio);
    }
    
    // 4. MEMORY OVERHEAD ANALYSIS
    println!("\nüíæ MEMORY OVERHEAD ANALYSIS");
    println!("{}", "=".repeat(50));
    
    use std::mem;
    
    println!("OptimizedArena<i32> size: {} bytes", mem::size_of::<OptimizedArena<i32>>());
    println!("CompactArena<i32> size: {} bytes", mem::size_of::<CompactArena<i32>>());
    
    let size_reduction = mem::size_of::<CompactArena<i32>>() - mem::size_of::<OptimizedArena<i32>>();
    println!("Size reduction: {} bytes ({:.1}%)", 
             size_reduction,
             size_reduction as f64 / mem::size_of::<CompactArena<i32>>() as f64 * 100.0);
    
    // 5. FRAGMENTATION ANALYSIS
    println!("\nüß© FRAGMENTATION ANALYSIS");
    println!("{}", "=".repeat(50));
    
    let mut opt_arena = OptimizedArena::new();
    let mut comp_arena = CompactArena::new();
    
    // Allocate and deallocate in a pattern that creates fragmentation
    let mut opt_ids = Vec::new();
    let mut comp_ids = Vec::new();
    
    // Allocate 1000 items
    for i in 0..1000 {
        opt_ids.push(opt_arena.allocate(i));
        comp_ids.push(comp_arena.allocate(i));
    }
    
    // Deallocate every other item
    for i in (0..1000).step_by(2) {
        opt_arena.deallocate(opt_ids[i]);
        comp_arena.deallocate(comp_ids[i]);
    }
    
    let opt_stats = opt_arena.stats();
    let comp_stats = comp_arena.stats();
    
    println!("After fragmentation pattern:");
    println!("  OptimizedArena utilization: {:.1}%", opt_stats.utilization * 100.0);
    println!("  CompactArena utilization: {:.1}%", comp_stats.utilization * 100.0);
    
    // 6. CACHE PERFORMANCE SIMULATION
    println!("\n‚ö° CACHE PERFORMANCE SIMULATION");
    println!("{}", "=".repeat(50));
    
    // Test cache-friendly vs cache-unfriendly access patterns
    let mut large_opt_arena = OptimizedArena::new();
    let mut large_comp_arena = CompactArena::new();
    let mut large_ids = Vec::new();
    
    for i in 0..50_000 {
        let opt_id = large_opt_arena.allocate(i);
        let comp_id = large_comp_arena.allocate(i);
        large_ids.push(opt_id);
    }
    
    // Sequential access (cache-friendly)
    let seq_start = Instant::now();
    let mut sum = 0i64;
    for &id in &large_ids {
        if let Some(value) = large_opt_arena.get(id) {
            sum += *value as i64;
        }
    }
    black_box(sum);
    let opt_sequential = seq_start.elapsed();
    
    let seq_start = Instant::now();
    let mut sum = 0i64;
    for &id in &large_ids {
        if let Some(value) = large_comp_arena.get(id) {
            sum += *value as i64;
        }
    }
    black_box(sum);
    let comp_sequential = seq_start.elapsed();
    
    println!("Sequential access (50k items):");
    println!("  OptimizedArena: {:.2}ms", opt_sequential.as_secs_f64() * 1000.0);
    println!("  CompactArena: {:.2}ms", comp_sequential.as_secs_f64() * 1000.0);
    
    let seq_ratio = comp_sequential.as_secs_f64() / opt_sequential.as_secs_f64();
    if seq_ratio > 1.0 {
        println!("  ‚úÖ OptimizedArena is {:.2}x FASTER", seq_ratio);
    } else {
        println!("  ‚ùå OptimizedArena is {:.2}x SLOWER", 1.0 / seq_ratio);
    }
    
    // 7. OVERALL PERFORMANCE SUMMARY
    println!("\nüìà PERFORMANCE SUMMARY");
    println!("{}", "=".repeat(50));
    
    println!("Operation        | Optimized | Compact   | Ratio    | Winner");
    println!("-----------------|-----------|-----------|----------|----------");
    println!("Allocation       | {:7.2}ms | {:7.2}ms | {:6.2}x | {}",
             optimized_alloc.as_secs_f64() * 1000.0,
             compact_alloc.as_secs_f64() * 1000.0,
             alloc_ratio,
             if alloc_ratio > 1.0 { "Optimized" } else { "Compact" });
    
    println!("Access           | {:7.2}ms | {:7.2}ms | {:6.2}x | {}",
             optimized_access.as_secs_f64() * 1000.0,
             compact_access.as_secs_f64() * 1000.0,
             access_ratio,
             if access_ratio > 1.0 { "Optimized" } else { "Compact" });
    
    println!("Mixed Operations | {:7.2}ms | {:7.2}ms | {:6.2}x | {}",
             optimized_mixed.as_secs_f64() * 1000.0,
             compact_mixed.as_secs_f64() * 1000.0,
             mixed_ratio,
             if mixed_ratio > 1.0 { "Optimized" } else { "Compact" });
    
    println!("Sequential Access| {:7.2}ms | {:7.2}ms | {:6.2}x | {}",
             opt_sequential.as_secs_f64() * 1000.0,
             comp_sequential.as_secs_f64() * 1000.0,
             seq_ratio,
             if seq_ratio > 1.0 { "Optimized" } else { "Compact" });
    
    // 8. RECOMMENDATIONS
    println!("\nüéØ PERFORMANCE RECOMMENDATIONS");
    println!("{}", "=".repeat(50));
    
    let overall_faster = alloc_ratio > 0.95 && access_ratio > 0.95 && mixed_ratio > 0.95;
    
    if overall_faster {
        println!("‚úÖ RECOMMENDATION: Use OptimizedArena");
        println!("   ‚Ä¢ Significant memory savings ({} bytes)", size_reduction);
        println!("   ‚Ä¢ Performance is equal or better");
        println!("   ‚Ä¢ Simpler implementation");
        println!("   ‚Ä¢ Better cache efficiency potential");
    } else {
        println!("‚ö†Ô∏è  RECOMMENDATION: Evaluate trade-offs");
        println!("   ‚Ä¢ Memory savings: {} bytes", size_reduction);
        println!("   ‚Ä¢ Performance trade-offs exist");
        println!("   ‚Ä¢ Consider workload characteristics");
    }
    
    println!("\nüîç DETAILED ANALYSIS");
    println!("{}", "=".repeat(50));
    println!("‚Ä¢ OptimizedArena removes allocated_mask Vec overhead");
    println!("‚Ä¢ Simplified free list management may impact reuse efficiency");
    println!("‚Ä¢ Smaller structure size improves cache locality");
    println!("‚Ä¢ Bit manipulation overhead is minimal (< 1ns per operation)");
}
